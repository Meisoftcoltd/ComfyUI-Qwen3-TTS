# ComfyUI Qwen3-TTS
Una suite de nodos personalizados de ComfyUI para [Qwen3-TTS](https://github.com/QwenLM/Qwen3-TTS), compatible con modelos de 1.7B y 0.6B, Voz Personalizada (Custom Voice), Dise√±o de Voz (Voice Design), Clonaci√≥n de Voz (Voice Cloning) y Fine-Tuning.

> üé§ **¬øBuscas Speech-to-Text?** Echa un vistazo a [ComfyUI-Qwen3-ASR](https://github.com/DarioFT/ComfyUI-Qwen3-ASR) para transcripci√≥n de audio con salidas compatibles.

<p align="center">
    <img src="https://raw.githubusercontent.com/DarioFT/ComfyUI-Qwen3-TTS/refs/heads/main/assets/intro.png"/>
<p>

## Caracter√≠sticas

- **Selector Din√°mico de Modelos**: Detecta autom√°ticamente modelos descargados y carpetas locales en `ComfyUI/models/tts/`.
- **Integraci√≥n con ComfyUI**: Los modelos se guardan organizados junto con otros modelos de ComfyUI.
- **Descarga bajo demanda**: Solo descarga el modelo que seleccionas, no todos los variantes.
- **Soporte completo de Qwen3-TTS**:
  - **Custom Voice**: Usa 9 voces preestablecidas de alta calidad (Vivian, Ryan, etc.).
  - **Voice Design**: Crea nuevas voces usando descripciones en lenguaje natural.
  - **Voice Cloning**: Clona voces a partir de un clip de audio de referencia corto.
- **Fine-Tuning**: Entrena un modelo de voz personalizado usando tu propio conjunto de datos (carpeta de archivos .wav + .txt).
  - Reanudaci√≥n de entrenamiento desde checkpoints.
  - Optimizaciones de VRAM: gradient checkpointing, AdamW de 8 bits, tama√±os de lote configurables.
  - Checkpoints por √©poca con limpieza autom√°tica.
  - Soporte para modelos de 1.7B y 0.6B.
- **Comparaci√≥n de Audio**: Eval√∫a modelos entrenados con m√©tricas de similitud de hablante y espectrograma mel.
- **Soporte Multiling√ºe**: Genera voz en chino, ingl√©s, japon√©s, coreano, alem√°n, franc√©s, ruso, portugu√©s, espa√±ol e italiano.
- **Atenci√≥n Flexible**: soporte robusto para `flash_attention_2` con retroceso autom√°tico a `sdpa` (atenci√≥n est√°ndar de PyTorch 2.0) si faltan dependencias.
- **Soporte WSL2**: Correcci√≥n autom√°tica de rutas para usuarios de WSL2 que acceden a discos de Windows (ej. `Z:\` se mapea a `/mnt/z/`).

## Instalaci√≥n

1.  Clona este repositorio en tu carpeta `ComfyUI/custom_nodes`:
    ```bash
    cd ComfyUI/custom_nodes
    git clone https://github.com/DarioFT/ComfyUI-Qwen3-TTS.git
    ```
2.  Instala las dependencias:
    ```bash
    cd ComfyUI-Qwen3-TTS
    pip install -r requirements.txt
    ```

    **For instalaciones portables/standalone de ComfyUI**, usa el Python integrado:
    ```bash
    # Desde tu carpeta ra√≠z ComfyUI_windows_portable
    .\python_embeded\python.exe -m pip install -r ComfyUI\custom_nodes\ComfyUI-Qwen3-TTS\requirements.txt
    ```

    > ‚ö†Ô∏è **Nota**: ComfyUI no instala autom√°ticamente las dependencias de `requirements.txt`. Debes ejecutar el comando de instalaci√≥n manualmente (o usar ComfyUI Manager).

    *Para aceleraci√≥n GPU, aseg√∫rate de tener instalado un PyTorch compatible con CUDA.*

## Almacenamiento de Modelos

Los modelos y tokenizers se guardan autom√°ticamente en tu carpeta de modelos de ComfyUI:
```
ComfyUI/models/tts/
‚îú‚îÄ‚îÄ Qwen3-TTS-12Hz-1.7B-CustomVoice/
‚îú‚îÄ‚îÄ Qwen3-TTS-12Hz-1.7B-VoiceDesign/
‚îú‚îÄ‚îÄ Qwen3-TTS-12Hz-1.7B-Base/
‚îú‚îÄ‚îÄ Qwen3-TTS-12Hz-0.6B-CustomVoice/
‚îú‚îÄ‚îÄ Qwen3-TTS-12Hz-0.6B-Base/
‚îú‚îÄ‚îÄ Qwen3-TTS-Tokenizer-12Hz/          # Para fine-tuning
‚îî‚îÄ‚îÄ prompts/                           # Embeddings de voz guardados (.safetensors)
```

**Primer uso**: Cuando seleccionas un modelo y ejecutas el flujo de trabajo por primera vez, se descargar√° autom√°ticamente.
**Modelos Locales**: Puedes colocar tus propias carpetas de modelos en este directorio y aparecer√°n autom√°ticamente en la lista del nodo Loader con el prefijo `Local:`.

## Uso

### 1. Cargar Modelo (üéôÔ∏è Qwen3-TTS Loader)
- **repo_id**: Selecciona el modelo que deseas usar.
  - Modelos `CustomVoice`: Para usar hablantes preestablecidos.
  - Modelos `VoiceDesign`: Para dise√±ar voces con descripciones de texto.
  - Modelos `Base`: Para clonaci√≥n de voz y fine-tuning.
  - Entradas `Local: ...`: Tus modelos personalizados detectados en la carpeta.
- **source**: Elige entre HuggingFace o ModelScope para descargar.
- **local_model_path**: (Opcional) Ruta forzada a un modelo local.
- **attention**: Deja en `auto` para el mejor rendimiento.

### 2. Generar Audio

Conecta el modelo cargado a uno de los nodos generadores:

#### **Custom Voice** (üó£Ô∏è Qwen3-TTS Custom Voice)
- **speaker**: Elige uno de los 9 preajustes (ej. Vivian, Ryan).
- **text**: El texto a hablar.
- **language**: Idioma objetivo (o Auto).
- **Par√°metros de Generaci√≥n**:
    - **top_p** (def: 0.8): Controla la diversidad.
    - **temperature** (def: 0.7): Controla la creatividad/aleatoriedad.
    - **repetition_penalty** (def: 1.1): Aumenta (ej. 1.2) si la generaci√≥n entra en bucles infinitos o repite palabras.

#### **Voice Design** (üé® Qwen3-TTS Voice Design)
- **instruct**: Describe la voz que quieres, ej. *"A deep, resonant male voice, narrator style, calm and professional."*
- **text**: El texto a hablar.
- **Par√°metros**: Iguales que en Custom Voice.

#### **Voice Clone** (üë• Qwen3-TTS Voice Clone)
- **ref_audio**: Sube un archivo de audio de referencia (1-10 segundos ideal).
- **ref_text**: La transcripci√≥n del audio de referencia (mejora la calidad).
- **text**: El texto para que la voz clonada hable.
- **max_new_tokens**: M√°ximo de tokens a generar.
- **ref_audio_max_seconds**: Auto-recorta el audio de referencia.
- **Par√°metros**: Iguales que en Custom Voice.

### 3. Avanzado: Cach√© de Prompts y Librer√≠as de Voz

Usa el nodo **Qwen3-TTS Prompt Maker** para precalcular las caracter√≠sticas de voz de un audio de referencia. Esto es m√°s r√°pido si generas muchas frases con la misma voz clonada.

#### Guardar Embeddings de Voz

Puedes guardar los prompts de clonaci√≥n de voz en disco para reutilizarlos:

1. **üíæ Qwen3-TTS Save Prompt**: Toma un `QWEN3_PROMPT` y lo guarda en `models/tts/prompts/`.
2. **üìÇ Qwen3-TTS Load Prompt**: Desplegable de prompts guardados.

## Fine-Tuning (Entrenamiento)

Entrena un modelo dedicado para una voz espec√≠fica.

1.  **Preparar Dataset**: Usa **üìÅ Qwen3-TTS Dataset Maker** para crear un `dataset.jsonl` desde una carpeta de archivos `.wav` y `.txt`.
2.  **Procesar Datos**: Usa **‚öôÔ∏è Qwen3-TTS Data Prep** para tokenizar el audio.
3.  **Fine-Tune**: Usa **üéì Qwen3-TTS Finetune**.
    - Conecta el `*_codes.jsonl`.
    - Selecciona un modelo base (1.7B o 0.6B).
    - Ajusta epochs y batch_size seg√∫n tu VRAM.
4.  **Evaluar**: Usa **üìä Qwen3-TTS Audio Compare**.
5.  **Usar Modelo Entrenado**:
    - Selecciona tu modelo en **Qwen3-TTS Loader** (aparecer√° como `Local: <nombre_carpeta>`).
    - Usa el nodo **Custom Voice**. Escribe el nombre exacto de tu hablante (`speaker_name`) en el campo `custom_speaker_name` si no aparece en la lista.

## Soluci√≥n de Problemas

### Bloqueos de Generaci√≥n / GPU al 100%

El modelo Qwen3-TTS puede entrar ocasionalmente en bucles de generaci√≥n infinita.

**Soluciones:**
1. **Aumentar `repetition_penalty`**: Prueba valores como 1.1 o 1.2. Esta es la soluci√≥n m√°s efectiva.
2. **Reducir `max_new_tokens`**: Prueba 1024 para salidas m√°s cortas.
3. **Usar audio de referencia m√°s corto**: Para clonaci√≥n de voz, 5-15 segundos es ideal.
4. **Matar el proceso Python** y reiniciar si se queda colgado.

### Inferencia lenta en Windows

Si no tienes FlashAttention 2 (com√∫n en Windows), la inferencia puede ser m√°s lenta.
- Configura **attention** en `sdpa` o `eager`.
- Considera usar WSL2.

### Problemas de rutas en WSL2 / "File Not Found"

Si ejecutas ComfyUI dentro de WSL2 pero accedes a archivos en un disco de Windows (ej. `Z:\mi_audio.wav`), esta suite de nodos convierte autom√°ticamente las rutas a sus equivalentes en WSL (ej. `/mnt/z/mi_audio.wav`).

**Depuraci√≥n:**
- Revisa la consola de ComfyUI en busca de mensajes que empiecen por `[Qwen3-TTS DEBUG]`. Estos registros muestran la conversi√≥n exacta de rutas, as√≠ como el conteo de archivos para la creaci√≥n de datasets y el progreso del entrenamiento.

## Cr√©ditos

Basado en la librer√≠a [Qwen3-TTS](https://github.com/QwenLM/Qwen3-TTS) de QwenLM.
