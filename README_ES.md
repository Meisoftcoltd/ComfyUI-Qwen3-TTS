# ComfyUI-Qwen3-TTS (Espa√±ol)

Nodos personalizados para [Qwen2.5-Audio / Qwen3-TTS](https://huggingface.co/Qwen/Qwen2.5-Audio-Instruct), un potente modelo de audio multimodal capaz de Text-to-Speech (TTS), Clonaci√≥n de Voz y Dise√±o de Voz.

## Caracter√≠sticas

*   **üéôÔ∏è Texto a Voz (TTS):** Genera voz de alta calidad a partir de texto en m√∫ltiples idiomas.
*   **üë• Clonaci√≥n de Voz:** Clona voces a partir de un clip de audio de referencia corto (se recomiendan 3-10s).
*   **üé® Dise√±o de Voz:** Dise√±a voces personalizadas describiendo atributos como g√©nero, edad, tono, velocidad y emoci√≥n.
*   **üéì Fine-Tuning y LoRA:** Flujo completo para realizar fine-tuning o entrenar adaptadores LoRA ligeros con tu propio dataset de voz.
*   **üìÅ Pipeline Modular de Dataset:** Automatiza la creaci√≥n de datasets: Cargar audio crudo -> Transcribir con Whisper -> Etiquetar emociones con Qwen2-Audio -> Exportar JSONL.
*   **‚öôÔ∏è Configuraci√≥n Avanzada:** Soluci√≥n para errores de "Unsupported speakers" en modelos fine-tuned y control detallado de prompts.

## Instalaci√≥n

1.  **Instala ComfyUI** (si no lo tienes ya).
2.  Clona este repositorio en tu carpeta `ComfyUI/custom_nodes/`:
    ```bash
    cd ComfyUI/custom_nodes/
    git clone https://github.com/your-repo/ComfyUI-Qwen3-TTS.git
    cd ComfyUI-Qwen3-TTS
    ```
3.  **Instala las dependencias:**
    ```bash
    pip install -r requirements.txt
    ```
    *Nota: Las funciones de entrenamiento requieren `peft`, `bitsandbytes` y `accelerate`. La creaci√≥n de datasets requiere `openai-whisper` y `pydub`.*

## Resumen de Nodos

### üéôÔ∏è Inferencia
*   **Qwen3Loader:** Carga el modelo base (ej. `Qwen/Qwen3-TTS-12Hz-1.7B-Base`).
*   **Qwen3LoadFineTuned:** Carga un modelo fine-tuned (checkpoint completo) e inyecta la configuraci√≥n de hablante personalizada necesaria para la inferencia.
*   **Qwen3ApplyLoRA:** Carga un adaptador LoRA (carpeta `.safetensors`) y lo aplica a un modelo base.
*   **Qwen3VoiceDesign:** Genera voz basada en texto y un conjunto de par√°metros opcionales (G√©nero, Tono, Emoci√≥n, etc.).
*   **Qwen3VoiceClone:** Genera voz clonando un audio de referencia.

### üìÅ Creaci√≥n de Dataset (Pipeline Modular)
1.  **Qwen3LoadDatasetAudio:** Escanea una carpeta en busca de archivos `.wav`.
2.  **Qwen3TranscribeWhisper:** Transcribe audio usando Whisper, recorta silencios y divide archivos largos. (Requiere `openai-whisper`).
3.  **Qwen3AutoLabelEmotions:** Usa `Qwen2-Audio-Instruct` para escuchar el audio y generar etiquetas descriptivas (emoci√≥n, g√©nero, tono) autom√°ticamente.
4.  **Qwen3ExportJSONL:** Exporta los datos procesados finales a un archivo `.jsonl` listo para entrenar.

### üéì Entrenamiento
*   **Qwen3DataPrep:** Pre-procesa el archivo JSONL convirti√©ndolo en tensores tokenizados (`input_ids`, `labels`) para un entrenamiento eficiente.
*   **Qwen3TrainLoRA:** Entrena un adaptador LoRA con los datos pre-procesados. Soporta configuraci√≥n de `rank`, `alpha`, `epochs`, etc.
*   **Qwen3FineTune:** (Legacy) L√≥gica de fine-tuning completo.

### üõ†Ô∏è Utilidades
*   **Qwen3SaveAudio:** Guarda lotes de audio generados en una subcarpeta espec√≠fica dentro del directorio de salida.
*   **Qwen3LoadAudioFromPath:** Carga audio desde una ruta absoluta (√∫til para pruebas).

## Consejos de Uso
*   **Dise√±o de Voz:** Usa los campos individuales (Gender, Pitch, etc.) para crear una voz espec√≠fica. No es necesario rellenarlos todos.
*   **Entrenamiento LoRA:** Ejecuta siempre **DataPrep** primero para generar el archivo `_codes.jsonl`. Esto acelera significativamente el entrenamiento al pre-calcular los tokens.
