# ComfyUI Qwen3-TTS
Una suite de nodos personalizados de ComfyUI para [Qwen3-TTS](https://github.com/QwenLM/Qwen3-TTS), compatible con modelos de 1.7B y 0.6B, Voz Personalizada (Custom Voice), DiseÃ±o de Voz (Voice Design), ClonaciÃ³n de Voz (Voice Cloning) y Fine-Tuning.

> ğŸ¤ **Â¿Buscas Speech-to-Text?** Echa un vistazo a [ComfyUI-Qwen3-ASR](https://github.com/DarioFT/ComfyUI-Qwen3-ASR) para transcripciÃ³n de audio con salidas compatibles.

<p align="center">
    <img src="https://raw.githubusercontent.com/DarioFT/ComfyUI-Qwen3-TTS/refs/heads/main/assets/intro.png"/>
<p>

## CaracterÃ­sticas

- **Selector DinÃ¡mico de Modelos**: Detecta automÃ¡ticamente modelos descargados y carpetas locales en `ComfyUI/models/tts/`.
- **IntegraciÃ³n con ComfyUI**: Los modelos se guardan organizados junto con otros modelos de ComfyUI.
- **Descarga bajo demanda**: Solo descarga el modelo que seleccionas, no todos los variantes.
- **Soporte completo de Qwen3-TTS**:
  - **Custom Voice**: Usa 9 voces preestablecidas de alta calidad (Vivian, Ryan, etc.).
  - **Voice Design**: Crea nuevas voces usando descripciones en lenguaje natural.
  - **Voice Cloning**: Clona voces a partir de un clip de audio de referencia corto.
- **Fine-Tuning**: Entrena un modelo de voz personalizado usando tu propio conjunto de datos (carpeta de archivos .wav + .txt).
  - ReanudaciÃ³n de entrenamiento desde checkpoints.
  - Optimizaciones de VRAM: gradient checkpointing, AdamW de 8 bits, tamaÃ±os de lote configurables.
  - Checkpoints por Ã©poca con limpieza automÃ¡tica.
  - Soporte para modelos de 1.7B y 0.6B.
- **ComparaciÃ³n de Audio**: EvalÃºa modelos entrenados con mÃ©tricas de similitud de hablante y espectrograma mel.
- **Soporte MultilingÃ¼e**: Genera voz en chino, inglÃ©s, japonÃ©s, coreano, alemÃ¡n, francÃ©s, ruso, portuguÃ©s, espaÃ±ol e italiano.
- **AtenciÃ³n Flexible**: soporte robusto para `flash_attention_2` con retroceso automÃ¡tico a `sdpa` (atenciÃ³n estÃ¡ndar de PyTorch 2.0) si faltan dependencias.

## InstalaciÃ³n

1.  Clona este repositorio en tu carpeta `ComfyUI/custom_nodes`:
    ```bash
    cd ComfyUI/custom_nodes
    git clone https://github.com/DarioFT/ComfyUI-Qwen3-TTS.git
    ```
2.  Instala las dependencias:
    ```bash
    cd ComfyUI-Qwen3-TTS
    pip install -r requirements.txt
    ```

    **For instalaciones portables/standalone de ComfyUI**, usa el Python integrado:
    ```bash
    # Desde tu carpeta raÃ­z ComfyUI_windows_portable
    .\python_embeded\python.exe -m pip install -r ComfyUI\custom_nodes\ComfyUI-Qwen3-TTS\requirements.txt
    ```

    > âš ï¸ **Nota**: ComfyUI no instala automÃ¡ticamente las dependencias de `requirements.txt`. Debes ejecutar el comando de instalaciÃ³n manualmente (o usar ComfyUI Manager).

    *Para aceleraciÃ³n GPU, asegÃºrate de tener instalado un PyTorch compatible con CUDA.*

## Almacenamiento de Modelos

Los modelos y tokenizers se guardan automÃ¡ticamente en tu carpeta de modelos de ComfyUI:
```
ComfyUI/models/tts/
â”œâ”€â”€ Qwen3-TTS-12Hz-1.7B-CustomVoice/
â”œâ”€â”€ Qwen3-TTS-12Hz-1.7B-VoiceDesign/
â”œâ”€â”€ Qwen3-TTS-12Hz-1.7B-Base/
â”œâ”€â”€ Qwen3-TTS-12Hz-0.6B-CustomVoice/
â”œâ”€â”€ Qwen3-TTS-12Hz-0.6B-Base/
â”œâ”€â”€ Qwen3-TTS-Tokenizer-12Hz/          # Para fine-tuning
â””â”€â”€ prompts/                           # Embeddings de voz guardados (.safetensors)
```

**Primer uso**: Cuando seleccionas un modelo y ejecutas el flujo de trabajo por primera vez, se descargarÃ¡ automÃ¡ticamente.
**Modelos Locales**: Puedes colocar tus propias carpetas de modelos en este directorio y aparecerÃ¡n automÃ¡ticamente en la lista del nodo Loader con el prefijo `Local:`.

## Uso

### 1. Cargar Modelo (ğŸ™ï¸ Qwen3-TTS Loader)
- **repo_id**: Selecciona el modelo que deseas usar.
  - Modelos `CustomVoice`: Para usar hablantes preestablecidos.
  - Modelos `VoiceDesign`: Para diseÃ±ar voces con descripciones de texto.
  - Modelos `Base`: Para clonaciÃ³n de voz y fine-tuning.
  - Entradas `Local: ...`: Tus modelos personalizados detectados en la carpeta.
- **source**: Elige entre HuggingFace o ModelScope para descargar.
- **local_model_path**: (Opcional) Ruta forzada a un modelo local.
- **attention**: Deja en `auto` para el mejor rendimiento.

### 2. Generar Audio

Conecta el modelo cargado a uno de los nodos generadores:

#### **Custom Voice** (ğŸ—£ï¸ Qwen3-TTS Custom Voice)
- **speaker**: Elige uno de los 9 preajustes (ej. Vivian, Ryan).
- **text**: El texto a hablar.
- **language**: Idioma objetivo (o Auto).
- **ParÃ¡metros de GeneraciÃ³n**:
    - **top_p** (def: 0.8): Controla la diversidad.
    - **temperature** (def: 0.7): Controla la creatividad/aleatoriedad.
    - **repetition_penalty** (def: 1.1): Aumenta (ej. 1.2) si la generaciÃ³n entra en bucles infinitos o repite palabras.

#### **Voice Design** (ğŸ¨ Qwen3-TTS Voice Design)
- **instruct**: Describe la voz que quieres, ej. *"A deep, resonant male voice, narrator style, calm and professional."*
- **text**: El texto a hablar.
- **ParÃ¡metros**: Iguales que en Custom Voice.

#### **Voice Clone** (ğŸ‘¥ Qwen3-TTS Voice Clone)
- **ref_audio**: Sube un archivo de audio de referencia (1-10 segundos ideal).
- **ref_text**: La transcripciÃ³n del audio de referencia (mejora la calidad).
- **text**: El texto para que la voz clonada hable.
- **max_new_tokens**: MÃ¡ximo de tokens a generar.
- **ref_audio_max_seconds**: Auto-recorta el audio de referencia.
- **ParÃ¡metros**: Iguales que en Custom Voice.

### 3. Avanzado: CachÃ© de Prompts y LibrerÃ­as de Voz

Usa el nodo **Qwen3-TTS Prompt Maker** para precalcular las caracterÃ­sticas de voz de un audio de referencia. Esto es mÃ¡s rÃ¡pido si generas muchas frases con la misma voz clonada.

#### Guardar Embeddings de Voz

Puedes guardar los prompts de clonaciÃ³n de voz en disco para reutilizarlos:

1. **ğŸ’¾ Qwen3-TTS Save Prompt**: Toma un `QWEN3_PROMPT` y lo guarda en `models/tts/prompts/`.
2. **ğŸ“‚ Qwen3-TTS Load Prompt**: Desplegable de prompts guardados.

## Fine-Tuning (Entrenamiento)

Entrena un modelo dedicado para una voz especÃ­fica.

1.  **Preparar Dataset**: Usa **ğŸ“ Qwen3-TTS Dataset Maker** para crear un `dataset.jsonl` desde una carpeta de archivos `.wav` y `.txt`.
2.  **Procesar Datos**: Usa **âš™ï¸ Qwen3-TTS Data Prep** para tokenizar el audio.
3.  **Fine-Tune**: Usa **ğŸ“ Qwen3-TTS Finetune**.
    - Conecta el `*_codes.jsonl`.
    - Selecciona un modelo base (1.7B o 0.6B).
    - Ajusta epochs y batch_size segÃºn tu VRAM.
4.  **Evaluar**: Usa **ğŸ“Š Qwen3-TTS Audio Compare**.
5.  **Usar Modelo Entrenado**:
    - Selecciona tu modelo en **Qwen3-TTS Loader** (aparecerÃ¡ como `Local: <nombre_carpeta>`).
    - Usa el nodo **Custom Voice**. Escribe el nombre exacto de tu hablante (`speaker_name`) en el campo `custom_speaker_name` si no aparece en la lista.

## SoluciÃ³n de Problemas

### Bloqueos de GeneraciÃ³n / GPU al 100%

El modelo Qwen3-TTS puede entrar ocasionalmente en bucles de generaciÃ³n infinita.

**Soluciones:**
1. **Aumentar `repetition_penalty`**: Prueba valores como 1.1 o 1.2. Esta es la soluciÃ³n mÃ¡s efectiva.
2. **Reducir `max_new_tokens`**: Prueba 1024 para salidas mÃ¡s cortas.
3. **Usar audio de referencia mÃ¡s corto**: Para clonaciÃ³n de voz, 5-15 segundos es ideal.
4. **Matar el proceso Python** y reiniciar si se queda colgado.

### Inferencia lenta en Windows

Si no tienes FlashAttention 2 (comÃºn en Windows), la inferencia puede ser mÃ¡s lenta.
- Configura **attention** en `sdpa` o `eager`.
- Considera usar WSL2.

## CrÃ©ditos

Basado en la librerÃ­a [Qwen3-TTS](https://github.com/QwenLM/Qwen3-TTS) de QwenLM.
